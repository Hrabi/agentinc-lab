{
  "AgenticLab": {
    "Runtime": {
      "Mode": "local",
      "MaxConcurrentAgents": 4,
      "DefaultTimeout": 30000
    },
    "Models": {
      "Default": {
        "Provider": "ollama",
        "Endpoint": "http://localhost:11434",
        "Model": "qwen2.5:14b",
        "MaxTokens": 2000,
        "Temperature": 0.7
      },
      "Fast": {
        "Provider": "ollama",
        "Endpoint": "http://localhost:11434",
        "Model": "llama3.2",
        "MaxTokens": 1000,
        "Temperature": 0.3
      },
      "Vllm": {
        "Provider": "openai-compatible",
        "Endpoint": "http://localhost:8000/v1",
        "ApiKey": "agenticlab-dev",
        "Model": "qwen2.5-14b",
        "MaxTokens": 2000,
        "Temperature": 0.7
      },
      "Embedding": {
        "Provider": "ollama",
        "Endpoint": "http://localhost:11434",
        "Model": "nomic-embed-text"
      }
    },
    "Routing": {
      "Default": "Default",
      "SimpleClassification": "Fast",
      "ComplexReasoning": "Default",
      "HighThroughput": "Vllm"
    },
    "Logging": {
      "Level": "Information"
    }
  }
}
