# AgenticLab Demo â€” Application Walkthrough

> What the demo does, how it works, and how all the pieces fit together.

---

## What Does the Demo Application Do?

The demo is an **interactive console chatbot** that:

1. Starts up and configures itself using .NET dependency injection
2. Connects to a **local LLM** running on your machine (Ollama)
3. Registers a **SimpleQuestionAgent** with the agent runtime
4. Opens an interactive loop where you type questions and get AI answers
5. Tracks token usage (prompt + completion tokens) for every interaction

It's the simplest possible agentic system â€” **one agent, one model, no tools** â€” designed to prove the entire pipeline works end-to-end before adding complexity.

---

## How It Works â€” Step by Step

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ You (Console)
    participant Program as ğŸ“‹ Program.cs
    participant Runtime as ğŸ”„ AgentRuntime
    participant Agent as ğŸ¤– SimpleQuestionAgent
    participant Model as ğŸ§  OllamaModel
    participant Ollama as ğŸ–¥ï¸ Ollama Server

    Note over Program: 1. Setup DI container
    Program->>Runtime: RegisterAgent(SimpleQuestionAgent)
    
    Note over User: 2. Interactive Loop
    User->>Program: Types a question
    Program->>Runtime: SendAsync("SimpleQuestion", request)
    Runtime->>Agent: ProcessAsync(request)
    Agent->>Model: GenerateAsync(modelRequest)
    Model->>Ollama: POST /api/generate (HTTP)
    Ollama-->>Model: JSON response + tokens
    Model-->>Agent: ModelResponse (text, token counts)
    Agent-->>Runtime: AgentResponse (message, metadata)
    Runtime-->>Program: AgentResponse
    Program-->>User: Prints [SimpleQuestion]: answer
```

---

## The 5 Projects â€” What Each One Does

```text
AgenticLab.sln
â”‚
â”œâ”€â”€ AgenticLab.Core          ğŸ§© Abstractions (interfaces + data models)
â”‚   â”œâ”€â”€ IAgent               â€” Contract for any agent
â”‚   â”œâ”€â”€ IModel               â€” Contract for any LLM backend
â”‚   â”œâ”€â”€ ITool                â€” Contract for any tool (not used yet)
â”‚   â”œâ”€â”€ AgentRequest/Response â€” Messages between runtime and agents
â”‚   â””â”€â”€ ModelRequest/Response â€” Messages between agents and models
â”‚
â”œâ”€â”€ AgenticLab.Runtime       ğŸ”„ Orchestration engine
â”‚   â””â”€â”€ AgentRuntime         â€” Registers agents, routes requests, handles errors
â”‚
â”œâ”€â”€ AgenticLab.Models        ğŸ§  LLM adapters
â”‚   â”œâ”€â”€ OllamaModel          â€” Talks to local Ollama via HTTP (âœ… implemented)
â”‚   â””â”€â”€ AzureOpenAIModel     â€” Talks to Azure OpenAI (ğŸš§ placeholder)
â”‚
â”œâ”€â”€ AgenticLab.Agents        ğŸ¤– Concrete agents
â”‚   â””â”€â”€ SimpleQuestionAgent  â€” Takes a question, sends to LLM, returns answer
â”‚
â””â”€â”€ AgenticLab.Demos         ğŸ¬ Entry point (the app you run)
    â””â”€â”€ Program.cs           â€” DI setup, agent registration, interactive loop
```

---

## Key Design Patterns in the Code

### 1. Dependency Injection (No Static Coupling)

```csharp
// Program.cs â€” everything is registered in the DI container
var services = new ServiceCollection();
services.AddSingleton<IModel>(sp => new OllamaModel(...));
services.AddTransient<SimpleQuestionAgent>();
services.AddSingleton<AgentRuntime>();
```

**Why?** Makes it trivial to swap Ollama for Azure OpenAI, or replace the agent â€” just change the registration.

### 2. Interface-Based Abstractions

```csharp
// The agent doesn't know or care if it's talking to Ollama, Azure, or vLLM
public class SimpleQuestionAgent : IAgent
{
    private readonly IModel _model;  // â† could be ANY model

    public async Task<AgentResponse> ProcessAsync(AgentRequest request, ...)
    {
        var response = await _model.GenerateAsync(...);  // â† polymorphic call
        return new AgentResponse { ... };
    }
}
```

**Why?** The agent is model-agnostic. Tomorrow you can plug in GPT-5.2 without changing agent code.

### 3. Runtime as Orchestrator

```csharp
// AgentRuntime routes requests to the right agent by name
runtime.RegisterAgent(agent);
var response = await runtime.SendAsync("SimpleQuestion", request);
```

**Why?** When you have multiple agents, the runtime decides who handles what. Foundation for multi-agent orchestration.

### 4. Structured Request/Response Models

```csharp
// Every layer has its own typed messages
AgentRequest  â†’ { Message, Metadata, History }
AgentResponse â†’ { AgentName, Message, Success, Metadata }
ModelRequest  â†’ { Prompt, SystemPrompt, MaxTokens, Temperature }
ModelResponse â†’ { Text, ModelName, PromptTokens, CompletionTokens }
```

**Why?** Clear boundaries. Agents speak "agent language", models speak "model language". No leaky abstractions.

---

## Data Flow â€” What Happens When You Ask "What is .NET?"

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ YOU type: "What is .NET?"                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Program.cs creates:                                                 â”‚
â”‚   AgentRequest { Message = "What is .NET?" }                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AgentRuntime.SendAsync("SimpleQuestion", request)                   â”‚
â”‚   â†’ Looks up agent by name in dictionary                            â”‚
â”‚   â†’ Calls agent.ProcessAsync(request)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SimpleQuestionAgent.ProcessAsync(request)                           â”‚
â”‚   â†’ Wraps your question into a ModelRequest:                        â”‚
â”‚     { Prompt = "What is .NET?",                                     â”‚
â”‚       SystemPrompt = "You are a helpful assistant...",              â”‚
â”‚       MaxTokens = 500, Temperature = 0.7 }                         â”‚
â”‚   â†’ Calls _model.GenerateAsync(modelRequest)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OllamaModel.GenerateAsync(modelRequest)                             â”‚
â”‚   â†’ HTTP POST to http://localhost:11434/api/generate                â”‚
â”‚     Body: { model: "llama3.2", prompt: "What is .NET?",            â”‚
â”‚             system: "You are a helpful assistant...",               â”‚
â”‚             stream: false, options: { temperature: 0.7 } }         â”‚
â”‚   â†’ Reads JSON response                                            â”‚
â”‚   â†’ Returns ModelResponse { Text = "...", PromptTokens, ... }      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Response flows back up:                                             â”‚
â”‚   ModelResponse â†’ Agent wraps into AgentResponse                    â”‚
â”‚   AgentResponse â†’ Runtime returns to Program.cs                     â”‚
â”‚   Program.cs â†’ Prints: "[SimpleQuestion]: .NET is a..."            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## What's NOT Implemented Yet (Roadmap)

| Feature | Status | Next Step |
|---------|--------|-----------|
| Single agent (SimpleQuestion) | âœ… Done | â€” |
| Ollama adapter | âœ… Done | â€” |
| AgentRuntime orchestration | âœ… Done | â€” |
| Azure OpenAI adapter | ğŸš§ Placeholder | Implement `GenerateAsync` |
| IModelRouter (hybrid routing) | ğŸ“‹ Planned | Route local vs cloud |
| ITool usage (agents with tools) | ğŸ“‹ Planned | File system, web search, code runner |
| Multi-agent collaboration | ğŸ“‹ Planned | Agents delegating to each other |
| Conversation history/memory | ğŸ“‹ Planned | `AgentRequest.History` is defined but unused |
| Configuration from appsettings | ğŸ“‹ Planned | Replace hardcoded endpoint/model |
| vLLM adapter | ğŸ“‹ Planned | OpenAI-compatible adapter |

---

## Running the Demo

### Prerequisites

```powershell
# 1. Install Ollama natively
winget install Ollama.Ollama

# 2. Pull a model
ollama pull llama3.2

# 3. Verify it's running
ollama list
```

### Run

```powershell
# From VS Code: press F5
# Or from terminal:
dotnet run --project src/AgenticLab.Demos
```

### Expected Output

```text
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        AgenticLab â€” Demo             â•‘
â•‘   Simple Question Agent              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Registered agents: SimpleQuestion

Type a question (or 'quit' to exit):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

> What is an agentic system?

[SimpleQuestion]: An agentic system is a software architecture where
autonomous agents receive goals, plan how to achieve them, use tools
to take actions, and produce results with minimal human intervention...
```

---

## Architecture â€” Where This Is Heading

```mermaid
flowchart TB
    subgraph Today["âœ… What works today"]
        Demo[Program.cs] --> Runtime[AgentRuntime]
        Runtime --> SQA[SimpleQuestionAgent]
        SQA --> Ollama[OllamaModel<br/>llama3.2 @ localhost:11434]
    end

    subgraph Next["ğŸ“‹ What's next"]
        Runtime2[AgentRuntime] --> Router{IModelRouter}
        Router -->|Simple| Local[OllamaModel<br/>qwen2.5:14b]
        Router -->|Complex| Cloud[AzureOpenAIModel<br/>GPT-5.2]
        Runtime2 --> ToolAgent[Tool-Using Agent]
        ToolAgent --> FileSystem[ğŸ“‚ File Tool]
        ToolAgent --> WebSearch[ğŸ” Search Tool]
        Runtime2 --> MultiAgent[Multi-Agent<br/>Orchestration]
    end

    Today -.->|evolves into| Next
```

---

*AgenticLab Demo Walkthrough â€” February 2026*
